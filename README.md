# ğŸ“„ RAG-based Document Question Answering System

This project is a **Retrieval-Augmented Generation (RAG)** system that allows users to **ask questions based on uploaded documents** (TXT or PDF). It retrieves the most relevant pieces of content from your document corpus and uses a language model to generate an accurate, context-aware answer.

---

## ğŸš€ Features

- âœ… Ask questions in natural language
- ğŸ“‚ Supports `.txt` and `.pdf` documents
- ğŸ” Uses FAISS for fast vector similarity search
- ğŸ¤– Powered by open-source embeddings and LLMs (Flan-T5 / MiniLM)
- ğŸ§  Retrieval-Augmented Generation pipeline (Retriever + Generator)
- ğŸ–¥ï¸ Streamlit app with user-friendly interface

---

## ğŸ§  How It Works (RAG)

1. **Document Loading**: Loads `.txt` or `.pdf` files from the `docs/` folder.
2. **Chunking**: Splits documents into overlapping chunks using LangChain.
3. **Embedding**: Encodes the chunks using `sentence-transformers` (e.g., `all-MiniLM-L6-v2`).
4. **Vector Store**: Stores embeddings in FAISS for fast similarity search.
5. **Retrieval**: Retrieves top-k relevant chunks for a user query.
6. **Generation**: Passes retrieved content to an open-source LLM (like `flan-t5-base`) to generate the final answer.

---

## ğŸ› ï¸ Tech Stack

| Component    | Tool / Model                    |
|--------------|---------------------------------|
| Framework    | [LangChain](https://github.com/langchain-ai/langchain) |
| UI           | Streamlit                       |
| Embeddings   | `all-MiniLM-L6-v2`              |
| Generator    | `flan-t5-base` (via HuggingFace)|
| Vector Store | FAISS                           |
| Language     | Python 3.10+                    |

---

## ğŸ“ Project Structure

rag_qa_project/
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ rag_qa.py # Core RAG logic
â”œâ”€â”€ docs/ # Folder to hold documents (.txt/.pdf)
â”‚ â””â”€â”€ example.txt
â”œâ”€â”€ .env # (optional for OpenAI API if needed)
â””â”€â”€ README.md
